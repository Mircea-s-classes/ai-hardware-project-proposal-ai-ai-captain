# AI Detector Project Report

## Project Information
- **Project Name:** Ai Ai Captain â€“ MonkAI Detector
- **Authors: Argie Cunanan James Jiang** 
- **Affiliation / Course: AI Hardware**
- **Date: December 15,2025**
- **GitHub Repository: https://github.com/Mircea-s-classes/ai-hardware-project-proposal-ai-ai-captain**

---

## Abstract
This report describes the goal, methodology, and results of the MonkAI Detector Project. The purpose of this project is to detect and classify hand poses using the OpenMV Cam H7 through lightweight machine learning techniques. The system uses a neural network trained with labeled image data and runs inference directly on the embedded device. The project demonstrates real-time gesture recognition with visual feedback and low latency, highlighting the feasibility of edge-based AI deployment.

---

## 1. Introduction
Artificial intelligence and embedded machine learning have enabled real-time perception tasks on low-power hardware. This project explores the use of an embedded vision system to recognize and classify hand gestures using an on-device neural network. By leveraging Edge Impulse and the OpenMV Cam H7, the MonkAI Detector Project demonstrates how gesture recognition can be performed without reliance on cloud computing. The project evaluates the effectiveness of pose classification on constrained hardware and highlights challenges such as limited memory, lighting variation, and dataset quality.

---

## 2. Project Goal
The primary goals of this project are:
- To deploy a lightweight neural network-based gesture classifier on embedded hardware using the OpenMV Cam H7
- To recognize and classify **three distinct hand gestures** in real time
- To perform **on-device (edge) inference** with minimal latency
- To provide **visual feedback** confirming the detected gesture


---

## 3. Methodology
This project was developed using **Edge Impulse** and the **OpenMV Cam H7**. An Edge Impulse account was created and a new project was initialized. Image samples of different hand poses were captured using the OpenMV camera and labeled accordingly. These images were uploaded to Edge Impulse and split into training and testing datasets. A neural network model was then trained and optimized for embedded deployment. After training, the model was exported and deployed to the OpenMV Cam H7 for real-time inference.

### 3.1 System Design
The MonkAI Detector consists of:
- An **image acquisition module** using the OpenMV camera
- A **feature extraction and classification pipeline** generated by Edge Impulse
- A **gesture classification output**, displayed through visual indicators on the device

Captured images are processed locally, and the trained model outputs the predicted gesture class.

### 3.2 Implementation Details
- **Programming language(s):** Python (MicroPython)
- **Libraries / frameworks used:** OpenMV firmware, Edge Impulse SDK
- **Detection technique:** Convolutional Neural Network (CNN) for image classification
- **Input format:** Grayscale or RGB images captured by the OpenMV camera
- **Output format:** Gesture label with confidence score
---

## 4. Procedure
The project followed these steps:
1. Captured images of three distinct hand gestures using the OpenMV Cam H7
2. Labeled and uploaded images to Edge Impulse
3. Split data into training and testing sets
4. Trained and validated a neural network model
5. Deployed the trained model to the OpenMV Cam H7
6. Performed real-time testing and observed classification results

---

## 5. Results
The system successfully classified hand gestures in real time under controlled lighting conditions. Results include:
- **High classification accuracy** for well-lit and clearly defined gestures
- Occasional misclassification under poor lighting or partial occlusion
- Stable real-time performance with minimal inference delay

---

## 6. Discussion
The results demonstrate that embedded gesture recognition is feasible using lightweight neural networks. The system performed reliably for distinct gestures but showed limitations when gestures were ambiguous or lighting conditions varied. Improvements could include collecting more diverse training data, adjusting camera exposure, and refining model parameters.

---

## 7. Conclusion
The MonkAI Detector Project demonstrates the successful deployment of an embedded gesture recognition system using Edge Impulse and the OpenMV Cam H7. The project highlights the strengths and limitations of edge AI and provides a foundation for future improvements such as additional gestures, improved robustness, and expanded applications.

---

## 8. Usage Instructions
To run or use the project:

```bash
# Example
pip install -r requirements.txt
python main.py
